       Building upon established end-to-end architectures, we propose a relative positional encoding-based end-to-end speech recognition model that incorporates the Learn Spelling from Teacher (LST) fusion language model (LST-RPESR). It incorporates a Multi-Residual Convolutional (MRC) module featuring a three-stream CNN architecture to extract and integrate feature information across multiple scales. Additionally, the deep feedforward sequential memory network (DFSMN) is improved by changing the distribution and the connection of memory modules to combine with the MRC to better capture contextual information within sequences. Furthermore, to tackle the issue of inadequate utilization of location information in the Transformer language model, relative positional factors are introduced into the self-attention mechanism for capturing of long-distance dependencies, with (Gated Linear Unit) GLU-Multihead-Attention proposed to enhance the Transformer language model's capability to process and distinguish key semantic information. 
